tree_rpart = rpart(V2~., sdized[trainv,])#
pred_rpart = predict(tree_rpart, newdata=sdized[-trainv,],type="class")#
M_list = confmatrix(sdized$V2[-trainv], pred_rpart)#
error_rpart = M_list$error#
#
exact_rpart = binom.test(x=n - round(error_rpart*n, digits=0), n=n, p=0.05)#
#
accv1 <- (sdized[-trainv,]$V2 == predict(tree_rpart, sdized[-trainv,], type='class'))#
accv2 <- (sdized[-trainv,]$V2 == predict(pred_knn, sdized[-trainv,]))
accv2 <- (sdized[-trainv,]$V2 == predict(pred_knn, sdized[-trainv,]), type='class')
accv2 <- (sdized[-trainv,]$V2 == predict(pred_knn, sdized[-trainv,], type='class'))
accv1 <- (sdized[-trainv,]$V2 == predict(tree_rpart, sdized[-trainv,], type='class'))
accv2 <- (sdized[-trainv,]$V2 == predict(pred_knn, sdized[-trainv,]))
accv2 <- (sdized[-trainv,]$V2 == pred_knn)#predict(pred_knn, sdized[-trainv,]))
mcnemartable = table(accv1, accv2)#
mcnemar.exact(mcnemartable)
#dataset functions: #
#
#splitdata - splits a dataframe into test and train sets#
#  inputs: #
#    1. dataset to be split#
#    2. (decimal) percent to be used for training set#
#    3. boolean to decide whether to take a sample with replacement#
#  output: #
#    list of length 3, #
#    list[[1]] = traindata#
#    list[[2]] = testdata#
#    list[[3]] = train (vector of indices from original set for train)#
#
#kfold_val - performs cross-validation on a dataset#
#  inputs:#
#    1. integer (k) for how many folds to use.#
#    2. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    3. data set #
#    4. column index for which variable is being predicted#
#  output: #
#    avg. error for either ctree or rpart w.r.t. dataset#
#
#error_leave_one_out - performs leave-one-out cross-validation.#
#  inputs: #
#    1. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    2. data set #
#    3. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#delete_d_cv - performs delte-d cross validation#
#  inputs: #
#    1. integer: number of times to iterate (m)#
#    2. integer: number of entries to leave out (d)#
#    3. type (0 or 1) for ctree or rpart respectively#
#    4. data set#
#    5. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#bootstrap - performs bootstrap validation#
#  inputs:#
#    1. integer: number of times to iterate (b)#
#    2. type(0 or 1) for (ctree, rpart) resp.#
#    3. data set#
#    4. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#confmatrix - compute the confusionmatrix for a tree w.r.t. #
#             predicted variable V#
#  inputs: #
#    1. V the predicted variable#
#    2. prediction method #
#  outputs: #
#    1. list with entries: #
#       1.1: table of predicted vs. actual V#
#       1.2: accuracy#
#       1.3: error#
#
#standardize - scale data in set with normal #
#  inputs #
#
splitdata = function(data, trainfrac, rep){#
	if((trainfrac > 1) | (trainfrac < 0)){#
		print("error in function splitdata: trainfrac not in [0 1]")#
	}#
#
	tot_size = nrow(data)#
	train_list = sample(tot_size, round(trainfrac * tot_size, digits=0), #
	                    replace = rep)#
	traindata <- data[train_list, ]#
	testdata <- data[-train_list, ]#
	mylist <- list(traindata = traindata, testdata = testdata, train = train_list)#
    return(mylist)#
}#
#
kfold_val = function(k, treetype, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
error_leave_one_out = function(treetype, wdbc, idx){#
	myerror = kfold_val(nrow(wdbc), treetype, wdbc, idx)#
	return(myerror)#
}#
#
delete_d_cv = function(m, d, mytree, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
#
  for(i in 1:m){#
	splitlist <- splitdata(wdbc, 1 - d / nrow(wdbc), FALSE)#
    traindata <- splitlist$traindata#
    testdata <- splitlist$testdata#
    if(mytree < 1){#
      mynewtree = ctree(mynewtestidx~., traindata)#
    }else{#
      mynewtree = rpart(mynewtestidx)~., traindata, type='class')#
    }#
#
    p_tree_train <- predict(mynewtree, testdata)#
#
    m_tree = table(testdata$mynewtestidx, p_tree_train)#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / m#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
bootstrap = function(b, mytree, wdbc, idx){#
	n1 <- names(wdbc)[idx]#
	names(wdbc)[idx] <- 'mynewidx'#
    total_acc = 0#
    n = nrow(wdbc)#
    for(i in 1:b){#
      	 splitlist <- splitdata(wdbc, 1, TRUE)#
      	 traindata <- splitlist$traindata#
      	 testdata <- splitlist$testdata#
      	 if(mytree < 1){#
      	 	mynewtree = ctree(mynewidx~., traindata)#
      	 }else{#
      	    mynewtree = rpart(mynewidx~., traindata)	#
      	 }#
      	 p_tree_train <- predict(mynewtree, testdata)#
   	     m_tree = table(testdata$mynewidx, p_tree_train)#
   	     test_acc = sum(diag(m_tree)) / sum(m_tree)#
   	     total_acc = total_acc + test_acc#
    }#
#
    names(wdbc)[idx] <- n1#
    total_acc = total_acc / b#
    return(1 - total_acc)#
}#
#
euclidean = function(x1, x2){#
  return(sqrt((x1 - x2) %*% (x1 - x2)))#
}#
#
confmatrix = function(y, predy){#
  matrix = table(y, predy)#
  accuracy = sum(diag(matrix))/sum(matrix)#
  return(list(matrix=matrix,accuracy=accuracy,error=1 - accuracy))#
}#
#
standardize = function(myset, cols){#
#
 xbar <- apply(myset[,cols], 2, mean) # mean for each column#
 s <- apply(myset[,cols], 2, sd)      # standard dev. for each col.#
#
 xbarMatrix <- cbind(rep(1,nrow(myset))) %*% xbar # matrix with each row xbar#
 sMatrix <- cbind(rep(1,nrow(myset))) %*% s       # matrix with each row s#
#
 sdized <- (myset[,cols] - xbarMatrix)#
 sdized <- sdized / sMatrix#
 sdized <- cbind(V2 = myset[,1], sdized[,1:ncol(sdized),drop=F])#
#
 return(sdized)#
}
# Data Mining hw 8#
library(e1071)#
data(houseVotes84, package='pmml')#
#
#1. For the following problems, consult the HouseVotes84 #
#   data set. #
#
##a. What is the probability that a randomly selected #
##   representative is a Democrat? #
  print(sum(houseVotes84$Class == 'democrat')/nrow(houseVotes84))#
  # probability is 61% it wil be a Democrat#
#
  # alt way: #
  print(table(houseVotes84$Class) / sum(table(houseVotes84$Class)))#
#
##b. Given that a representative is a Republican, what #
##   is the probability that he or she voted for water #
##   project cost sharing? #
#
  repwater <- naiveBayes(V2~Class, houseVotes84)#
#
  ##Verify by hand computation of Bayes formula: #
  rep <- (houseVotes84$Class == 'republican') * 1#
  dem <- (houseVotes84$Class == 'democrat') * 1#
#
  idx <- 1 - (is.na(houseVotes84$V2) * 1) #
  v2 <- houseVotes84$V2[complete.cases(houseVotes84$V2)]#
#
  prob_water = sum( (v2 == 'y') * 1) / length(v2)#
  prob_nwater = sum((v2 == 'n') * 1) / length(v2)#
  prob_rep = sum(rep) / nrow(houseVotes84)#
  prob_dem = sum(dem) / nrow(houseVotes84)#
  p_w_rep = sum( (v2 == 'y') & (rep[idx == 1] > 0) ) / (sum(rep))#
  p_w_dem = sum( (v2 == 'y') & (dem[idx == 1] > 0) ) / (sum(dem))#
#
  # probability is 0.3846154 by both computations.#
#
##c. Given that a representative voted for adoption of the #
##   budget resolution, against the physician fee freeze and #
##   duty free exports, find the probability that he or she #
##   is a Democrat (Hint: if x is a vector, you can use #
##   rbind(x) to force R to treat it as a row vector. You can #
##   set missing values of x to NA, and naive Bayes will #
##   ignore them.)#
###
##      i.e. We're checking probability that#
##        Class == 'democrat' given #
##        V3 = 'y'#
##        V4 = 'n'#
##        V15 = 'n'#
#
  dem3415 <- naiveBayes(Class~V3 + V4 + V15, houseVotes84)#
  dvec <- rbind(rep('NA', 17))#
  dvec[4] <- 'y'#
  dvec[5] <- 'n'#
  dvec[16] <- 'n'#
  predict(dem3415, newdata = dvec, type='raw')#
#
#2. Investigate normality of the quantitative variables in the #
#   wdbc.data data set, using Shapiro-Wilk tests, histograms, #
#   and qq-plots. #
  wdbc <- read.table('~/Dropbox/Tarleton/data_mining/hw05/wdbc.data',#
                     header=F,sep=',')#
  wdbc <- wdbc[,-1]#
  names(wdbc)[1] <- c('diagnosis')#
  hist(wdbc$V3)#
  shapiro.test(wdbc$V3) # returns a p-value of 3.106e-14#
  qqnorm(wdbc$V3)#
#
#3. After splitting wdbc.data into 70% training and 30% test #
#   data, compare the test accuracies of naive Bayes, treating #
#   the quantitative variables as #
#
  splitset <- splitdata(wdbc, 0.7, FALSE)#
  train_d <- splitset$traindata#
  test_d  <- splitset$testdata#
  train_i <- splitset$train#
#
##a. normally distributed variables#
  pred_diag_n <- naiveBayes(diagnosis ~., wdbc)#
  pred <- predict(pred_diag_n, wdbc)#
  table(pred, wdbc$diagnosis)#
  err_normal = confmatrix(wdbc$diagnosis, pred)$error#
#
##b. categorical variables with 4 levels. #
#
  disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
    disc_wdbc[,j] <- as.factor(cut(wdbc[,j], 4))#
  }#
  pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc)#
  pred <- predict(pred_diag_n, disc_wdbc)#
  table(pred, disc_wdbc$diagnosis)#
  err_cat = confmatrix(disc_wdbc$diagnosis, pred)$error#
#
#4. Use 10-fold cross validation to estimate the accuracy of #
#   naive Bayes on wdbc.data, treating the quantitative #
#   variables as #
#
##a. normally distributed variables#
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)#
#
##b. categorical variables with L levels, L = 2, 3, ... , 10.#
  nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- as.factor(cut(wdbc[,j], L))#
    }#
    err_k10_cat[L] <- kfold_val(10, disc)#
  }#
#
  kfold_val = function(k, wdbc){#
    total_acc = 0#
    size = ceiling(nrow(wdbc)/k)#
    folds = sample(rep(1:k,size))#
    myvec = folds[1:nrow(wdbc)]#
#
    for(i in 1:k){#
#
      testdata <- wdbc[myvec==i,]#
      traindata <- wdbc[myvec!=i,]#
      mynewtree <- naiveBayes(diagnosis~., data=traindata)#
#
      p_tree_train <- predict(mynewtree, testdata)#
      m_tree = table(wdbc$d[myvec==i], p_tree_train)#
#
      test_acc = (sum(diag(m_tree)) / sum(m_tree))#
      total_acc = total_acc + test_acc#
    }#
    total_acc = total_acc / k#
    return(1 - total_acc)#
  }#
#
#5. Investigate the effect of the Laplace smoothing argument in #
#   the naiveBayes function. What appears to be the optimal value#
#   for this argument?
##a. normally distributed variables#
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)#
#
##b. categorical variables with L levels, L = 2, 3, ... , 10.#
  nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- as.factor(cut(wdbc[,j], L))#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }
#dataset functions: #
#
#splitdata - splits a dataframe into test and train sets#
#  inputs: #
#    1. dataset to be split#
#    2. (decimal) percent to be used for training set#
#    3. boolean to decide whether to take a sample with replacement#
#  output: #
#    list of length 3, #
#    list[[1]] = traindata#
#    list[[2]] = testdata#
#    list[[3]] = train (vector of indices from original set for train)#
#
#kfold_val - performs cross-validation on a dataset#
#  inputs:#
#    1. integer (k) for how many folds to use.#
#    2. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    3. data set #
#    4. column index for which variable is being predicted#
#  output: #
#    avg. error for either ctree or rpart w.r.t. dataset#
#
#error_leave_one_out - performs leave-one-out cross-validation.#
#  inputs: #
#    1. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    2. data set #
#    3. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#delete_d_cv - performs delte-d cross validation#
#  inputs: #
#    1. integer: number of times to iterate (m)#
#    2. integer: number of entries to leave out (d)#
#    3. type (0 or 1) for ctree or rpart respectively#
#    4. data set#
#    5. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#bootstrap - performs bootstrap validation#
#  inputs:#
#    1. integer: number of times to iterate (b)#
#    2. type(0 or 1) for (ctree, rpart) resp.#
#    3. data set#
#    4. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#confmatrix - compute the confusionmatrix for a tree w.r.t. #
#             predicted variable V#
#  inputs: #
#    1. V the predicted variable#
#    2. prediction method #
#  outputs: #
#    1. list with entries: #
#       1.1: table of predicted vs. actual V#
#       1.2: accuracy#
#       1.3: error#
#
#standardize - scale data in set with normal #
#  inputs #
#
splitdata = function(data, trainfrac, rep){#
	if((trainfrac > 1) | (trainfrac < 0)){#
		print("error in function splitdata: trainfrac not in [0 1]")#
	}#
#
	tot_size = nrow(data)#
	train_list = sample(tot_size, round(trainfrac * tot_size, digits=0), #
	                    replace = rep)#
	traindata <- data[train_list, ]#
	testdata <- data[-train_list, ]#
	mylist <- list(traindata = traindata, testdata = testdata, train = train_list)#
    return(mylist)#
}#
#
kfold_val = function(k, treetype, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
error_leave_one_out = function(treetype, wdbc, idx){#
	myerror = kfold_val(nrow(wdbc), treetype, wdbc, idx)#
	return(myerror)#
}#
#
delete_d_cv = function(m, d, mytree, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
#
  for(i in 1:m){#
	splitlist <- splitdata(wdbc, 1 - d / nrow(wdbc), FALSE)#
    traindata <- splitlist$traindata#
    testdata <- splitlist$testdata#
    if(mytree < 1){#
      mynewtree = ctree(mynewtestidx~., traindata)#
    }else{#
      mynewtree = rpart(mynewtestidx)~., traindata, type='class')#
    }#
#
    p_tree_train <- predict(mynewtree, testdata)#
#
    m_tree = table(testdata$mynewtestidx, p_tree_train)#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / m#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
bootstrap = function(b, mytree, wdbc, idx){#
	n1 <- names(wdbc)[idx]#
	names(wdbc)[idx] <- 'mynewidx'#
    total_acc = 0#
    n = nrow(wdbc)#
    for(i in 1:b){#
      	 splitlist <- splitdata(wdbc, 1, TRUE)#
      	 traindata <- splitlist$traindata#
      	 testdata <- splitlist$testdata#
      	 if(mytree < 1){#
      	 	mynewtree = ctree(mynewidx~., traindata)#
      	 }else{#
      	    mynewtree = rpart(mynewidx~., traindata)	#
      	 }#
      	 p_tree_train <- predict(mynewtree, testdata)#
   	     m_tree = table(testdata$mynewidx, p_tree_train)#
   	     test_acc = sum(diag(m_tree)) / sum(m_tree)#
   	     total_acc = total_acc + test_acc#
    }#
#
    names(wdbc)[idx] <- n1#
    total_acc = total_acc / b#
    return(1 - total_acc)#
}#
#
euclidean = function(x1, x2){#
  return(sqrt((x1 - x2) %*% (x1 - x2)))#
}#
#
confmatrix = function(y, predy){#
  matrix = table(y, predy)#
  accuracy = sum(diag(matrix))/sum(matrix)#
  return(list(matrix=matrix,accuracy=accuracy,error=1 - accuracy))#
}#
#
standardize = function(myset, cols){#
#
 xbar <- apply(myset[,cols], 2, mean) # mean for each column#
 s <- apply(myset[,cols], 2, sd)      # standard dev. for each col.#
#
 xbarMatrix <- cbind(rep(1,nrow(myset))) %*% xbar # matrix with each row xbar#
 sMatrix <- cbind(rep(1,nrow(myset))) %*% s       # matrix with each row s#
#
 sdized <- (myset[,cols] - xbarMatrix)#
 sdized <- sdized / sMatrix#
 sdized <- cbind(V2 = myset[,1], sdized[,1:ncol(sdized),drop=F])#
#
 return(sdized)#
}
for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- as.factor(cut(wdbc[,j], L))#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }
err_k10_cat
for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- as.factor(cut(wdbc[,j], L))#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }
err_k10_cat
#dataset functions: #
#
#splitdata - splits a dataframe into test and train sets#
#  inputs: #
#    1. dataset to be split#
#    2. (decimal) percent to be used for training set#
#    3. boolean to decide whether to take a sample with replacement#
#  output: #
#    list of length 3, #
#    list[[1]] = traindata#
#    list[[2]] = testdata#
#    list[[3]] = train (vector of indices from original set for train)#
#
#kfold_val - performs cross-validation on a dataset#
#  inputs:#
#    1. integer (k) for how many folds to use.#
#    2. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    3. data set #
#    4. column index for which variable is being predicted#
#  output: #
#    avg. error for either ctree or rpart w.r.t. dataset#
#
#error_leave_one_out - performs leave-one-out cross-validation.#
#  inputs: #
#    1. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    2. data set #
#    3. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#delete_d_cv - performs delte-d cross validation#
#  inputs: #
#    1. integer: number of times to iterate (m)#
#    2. integer: number of entries to leave out (d)#
#    3. type (0 or 1) for ctree or rpart respectively#
#    4. data set#
#    5. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#bootstrap - performs bootstrap validation#
#  inputs:#
#    1. integer: number of times to iterate (b)#
#    2. type(0 or 1) for (ctree, rpart) resp.#
#    3. data set#
#    4. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#confmatrix - compute the confusionmatrix for a tree w.r.t. #
#             predicted variable V#
#  inputs: #
#    1. V the predicted variable#
#    2. prediction method #
#  outputs: #
#    1. list with entries: #
#       1.1: table of predicted vs. actual V#
#       1.2: accuracy#
#       1.3: error#
#
#standardize - scale data in set with normal #
#  inputs #
#
splitdata = function(data, trainfrac, rep){#
	if((trainfrac > 1) | (trainfrac < 0)){#
		print("error in function splitdata: trainfrac not in [0 1]")#
	}#
#
	tot_size = nrow(data)#
	train_list = sample(tot_size, round(trainfrac * tot_size, digits=0), #
	                    replace = rep)#
	traindata <- data[train_list, ]#
	testdata <- data[-train_list, ]#
	mylist <- list(traindata = traindata, testdata = testdata, train = train_list)#
    return(mylist)#
}#
#
kfold_val = function(k, treetype, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
error_leave_one_out = function(treetype, wdbc, idx){#
	myerror = kfold_val(nrow(wdbc), treetype, wdbc, idx)#
	return(myerror)#
}#
#
delete_d_cv = function(m, d, mytree, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
#
  for(i in 1:m){#
	splitlist <- splitdata(wdbc, 1 - d / nrow(wdbc), FALSE)#
    traindata <- splitlist$traindata#
    testdata <- splitlist$testdata#
    if(mytree < 1){#
      mynewtree = ctree(mynewtestidx~., traindata)#
    }else{#
      mynewtree = rpart(mynewtestidx)~., traindata, type='class')#
    }#
#
    p_tree_train <- predict(mynewtree, testdata)#
#
    m_tree = table(testdata$mynewtestidx, p_tree_train)#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / m#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
bootstrap = function(b, mytree, wdbc, idx){#
	n1 <- names(wdbc)[idx]#
	names(wdbc)[idx] <- 'mynewidx'#
    total_acc = 0#
    n = nrow(wdbc)#
    for(i in 1:b){#
      	 splitlist <- splitdata(wdbc, 1, TRUE)#
      	 traindata <- splitlist$traindata#
      	 testdata <- splitlist$testdata#
      	 if(mytree < 1){#
      	 	mynewtree = ctree(mynewidx~., traindata)#
      	 }else{#
      	    mynewtree = rpart(mynewidx~., traindata)	#
      	 }#
      	 p_tree_train <- predict(mynewtree, testdata)#
   	     m_tree = table(testdata$mynewidx, p_tree_train)#
   	     test_acc = sum(diag(m_tree)) / sum(m_tree)#
   	     total_acc = total_acc + test_acc#
    }#
#
    names(wdbc)[idx] <- n1#
    total_acc = total_acc / b#
    return(1 - total_acc)#
}#
#
euclidean = function(x1, x2){#
  return(sqrt((x1 - x2) %*% (x1 - x2)))#
}#
#
confmatrix = function(y, predy){#
  matrix = table(y, predy)#
  accuracy = sum(diag(matrix))/sum(matrix)#
  return(list(matrix=matrix,accuracy=accuracy,error=1 - accuracy))#
}#
#
standardize = function(myset, cols){#
#
 xbar <- apply(myset[,cols], 2, mean) # mean for each column#
 s <- apply(myset[,cols], 2, sd)      # standard dev. for each col.#
#
 xbarMatrix <- cbind(rep(1,nrow(myset))) %*% xbar # matrix with each row xbar#
 sMatrix <- cbind(rep(1,nrow(myset))) %*% s       # matrix with each row s#
#
 sdized <- (myset[,cols] - xbarMatrix)#
 sdized <- sdized / sMatrix#
 sdized <- cbind(V2 = myset[,1], sdized[,1:ncol(sdized),drop=F])#
#
 return(sdized)#
}
library(e1071)#
data(houseVotes84, package='pmml')#
#
#1. For the following problems, consult the HouseVotes84 #
#   data set. #
#
##a. What is the probability that a randomly selected #
##   representative is a Democrat? #
  print(sum(houseVotes84$Class == 'democrat')/nrow(houseVotes84))#
  # probability is 61% it wil be a Democrat#
#
  # alt way: #
  print(table(houseVotes84$Class) / sum(table(houseVotes84$Class)))#
#
##b. Given that a representative is a Republican, what #
##   is the probability that he or she voted for water #
##   project cost sharing? #
#
  repwater <- naiveBayes(V2~Class, houseVotes84)#
#
  ##Verify by hand computation of Bayes formula: #
  rep <- (houseVotes84$Class == 'republican') * 1#
  dem <- (houseVotes84$Class == 'democrat') * 1#
#
  idx <- 1 - (is.na(houseVotes84$V2) * 1) #
  v2 <- houseVotes84$V2[complete.cases(houseVotes84$V2)]#
#
  prob_water = sum( (v2 == 'y') * 1) / length(v2)#
  prob_nwater = sum((v2 == 'n') * 1) / length(v2)#
  prob_rep = sum(rep) / nrow(houseVotes84)#
  prob_dem = sum(dem) / nrow(houseVotes84)#
  p_w_rep = sum( (v2 == 'y') & (rep[idx == 1] > 0) ) / (sum(rep))#
  p_w_dem = sum( (v2 == 'y') & (dem[idx == 1] > 0) ) / (sum(dem))#
#
  # probability is 0.3846154 by both computations.#
#
##c. Given that a representative voted for adoption of the #
##   budget resolution, against the physician fee freeze and #
##   duty free exports, find the probability that he or she #
##   is a Democrat (Hint: if x is a vector, you can use #
##   rbind(x) to force R to treat it as a row vector. You can #
##   set missing values of x to NA, and naive Bayes will #
##   ignore them.)#
###
##      i.e. We're checking probability that#
##        Class == 'democrat' given #
##        V3 = 'y'#
##        V4 = 'n'#
##        V15 = 'n'#
#
  dem3415 <- naiveBayes(Class~V3 + V4 + V15, houseVotes84)#
  dvec <- rbind(rep('NA', 17))#
  dvec[4] <- 'y'#
  dvec[5] <- 'n'#
  dvec[16] <- 'n'#
  predict(dem3415, newdata = dvec, type='raw')#
#
#2. Investigate normality of the quantitative variables in the #
#   wdbc.data data set, using Shapiro-Wilk tests, histograms, #
#   and qq-plots. #
  wdbc <- read.table('~/Dropbox/Tarleton/data_mining/hw05/wdbc.data',#
                     header=F,sep=',')#
  wdbc <- wdbc[,-1]#
  names(wdbc)[1] <- c('diagnosis')#
  hist(wdbc$V3)#
  shapiro.test(wdbc$V3) # returns a p-value of 3.106e-14#
  qqnorm(wdbc$V3)#
#
#3. After splitting wdbc.data into 70% training and 30% test #
#   data, compare the test accuracies of naive Bayes, treating #
#   the quantitative variables as #
#
  splitset <- splitdata(wdbc, 0.7, FALSE)#
  train_d <- splitset$traindata#
  test_d  <- splitset$testdata#
  train_i <- splitset$train#
#
##a. normally distributed variables#
  pred_diag_n <- naiveBayes(diagnosis ~., wdbc)#
  pred <- predict(pred_diag_n, wdbc)#
  table(pred, wdbc$diagnosis)#
  err_normal = confmatrix(wdbc$diagnosis, pred)$error#
#
##b. categorical variables with 4 levels. #
#
  disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
    disc_wdbc[,j] <- as.factor(cut(wdbc[,j], 4))#
  }#
  pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc)#
  pred <- predict(pred_diag_n, disc_wdbc)#
  table(pred, disc_wdbc$diagnosis)#
  err_cat = confmatrix(disc_wdbc$diagnosis, pred)$error#
#
#4. Use 10-fold cross validation to estimate the accuracy of #
#   naive Bayes on wdbc.data, treating the quantitative #
#   variables as #
#
##a. normally distributed variables#
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)#
#
##b. categorical variables with L levels, L = 2, 3, ... , 10.#
  nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- as.factor(cut(wdbc[,j], L))#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }
err_10_cat
err_k10_cat
nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- as.factor(cut(wdbc[,j], L))#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }
err_k10_cat
plot(err_k10_cat, 1:L)
plot(err_k10_cat, v1 = 1:L, col=v1)
plot(err_k10_cat, v1 = 1:L, col=c('black','blue','green','yellow','orange','red','purple','brown','gray','pink')[v1])
v1 = 1:L#
  plot(err_k10_cat, v1, col=c('black','blue','green','yellow','orange','red','purple','brown','gray','pink')[v1])
lines(err_k10_cat, v1, type='l')
plot(v1, err_k10_cat, col=c('black','blue','green','yellow','orange','red','purple','brown','gray','pink')[v1])
col=c('black','blue','green','yellow','orange','red','purple','brown','gray','pink')[v1], xlab='# levels', ylab='average kfold error')#
#lines(err_k10_cat, v1, type='l')
plot(v1, err_k10_cat, xlab='# levels', ylab='average kfold error', col=c('black','blue','green','yellow','orange','red','purple','brown','gray','pink')[v1])
plot(v1, err_k10_cat, xlab='# levels', ylab='kfold error', col=c('black','blue','green','yellow','orange','red','purple','brown','gray','pink')[v1])
err_k10_normal1
which.min(err_k10_cat)
# Data Mining hw 8#
library(e1071)#
data(houseVotes84, package='pmml')#
#
#1. For the following problems, consult the HouseVotes84 #
#   data set. #
#
##a. What is the probability that a randomly selected #
##   representative is a Democrat? #
  print(sum(houseVotes84$Class == 'democrat')/nrow(houseVotes84))#
  # probability is 61% it wil be a Democrat#
#
  # alt way: #
  print(table(houseVotes84$Class) / sum(table(houseVotes84$Class)))#
#
##b. Given that a representative is a Republican, what #
##   is the probability that he or she voted for water #
##   project cost sharing? #
#
  repwater <- naiveBayes(V2~Class, houseVotes84)#
#
  ##Verify by hand computation of Bayes formula: #
  rep <- (houseVotes84$Class == 'republican') * 1#
  dem <- (houseVotes84$Class == 'democrat') * 1#
#
  idx <- 1 - (is.na(houseVotes84$V2) * 1) #
  v2 <- houseVotes84$V2[complete.cases(houseVotes84$V2)]#
#
  prob_water = sum( (v2 == 'y') * 1) / length(v2)#
  prob_nwater = sum((v2 == 'n') * 1) / length(v2)#
  prob_rep = sum(rep) / nrow(houseVotes84)#
  prob_dem = sum(dem) / nrow(houseVotes84)#
  p_w_rep = sum( (v2 == 'y') & (rep[idx == 1] > 0) ) / (sum(rep))#
  p_w_dem = sum( (v2 == 'y') & (dem[idx == 1] > 0) ) / (sum(dem))#
#
  # probability is 0.3846154 by both computations.#
#
##c. Given that a representative voted for adoption of the #
##   budget resolution, against the physician fee freeze and #
##   duty free exports, find the probability that he or she #
##   is a Democrat (Hint: if x is a vector, you can use #
##   rbind(x) to force R to treat it as a row vector. You can #
##   set missing values of x to NA, and naive Bayes will #
##   ignore them.)#
###
##      i.e. We're checking probability that#
##        Class == 'democrat' given #
##        V3 = 'y'#
##        V4 = 'n'#
##        V15 = 'n'#
#
  dem3415 <- naiveBayes(Class~V3 + V4 + V15, houseVotes84)#
  dvec <- rbind(rep('NA', 17))#
  dvec[4] <- 'y'#
  dvec[5] <- 'n'#
  dvec[16] <- 'n'#
  predict(dem3415, newdata = dvec, type='raw')#
#
#2. Investigate normality of the quantitative variables in the #
#   wdbc.data data set, using Shapiro-Wilk tests, histograms, #
#   and qq-plots. #
  wdbc <- read.table('~/Dropbox/Tarleton/data_mining/hw05/wdbc.data',#
                     header=F,sep=',')#
  wdbc <- wdbc[,-1]#
  names(wdbc)[1] <- c('diagnosis')#
  hist(wdbc$V3)#
  shapiro.test(wdbc$V3) # returns a p-value of 3.106e-14#
  qqnorm(wdbc$V3)#
#
#3. After splitting wdbc.data into 70% training and 30% test #
#   data, compare the test accuracies of naive Bayes, treating #
#   the quantitative variables as #
#
  splitset <- splitdata(wdbc, 0.7, FALSE)#
  train_d <- splitset$traindata#
  test_d  <- splitset$testdata#
  train_i <- splitset$train#
#
##a. normally distributed variables#
  pred_diag_n <- naiveBayes(diagnosis ~., wdbc)#
  pred <- predict(pred_diag_n, wdbc)#
  table(pred, wdbc$diagnosis)#
  err_normal = confmatrix(wdbc$diagnosis, pred)$error#
#
##b. categorical variables with 4 levels. #
#
  disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
    disc_wdbc[,j] <- as.factor(cut(wdbc[,j], 4))#
  }#
  pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc)#
  pred <- predict(pred_diag_n, disc_wdbc)#
  table(pred, disc_wdbc$diagnosis)#
  err_cat = confmatrix(disc_wdbc$diagnosis, pred)$error#
#
#4. Use 10-fold cross validation to estimate the accuracy of #
#   naive Bayes on wdbc.data, treating the quantitative #
#   variables as #
#
##a. normally distributed variables#
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)#
#
# 0.6616758#
#
##b. categorical variables with L levels, L = 2, 3, ... , 10.#
  nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- as.factor(cut(wdbc[,j], L))#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }#
  v1 = 1:L#
  plot(v1, err_k10_cat, #
      xlab='# levels', ylab='kfold error',#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])#
#
# highest accuracy occurs when the number of levels is: #
which.min(err_k10_cat)#
#
#5. Investigate the effect of the Laplace smoothing argument in #
#   the naiveBayes function. What appears to be the optimal value#
#   for this argument?
plot(v1, err_k10_cat, #
      xlab='# levels', ylab='kfold error', type='p'#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
plot(v1, err_k10_cat, #
      xlab='# levels', ylab='kfold error', type='p', pty=16#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
plot(v1, err_k10_cat, #
      xlab='# levels', ylab='kfold error', type='p', pty=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
plot(v1, err_k10_cat, #
      xlab='# levels', ylab='kfold error', type='p', pch=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
which.min(err_k10_cat)
plot(v1, err_k10_cat[2:L], #
      xlab='# levels', ylab='kfold error', type='p', pch=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
v1 = 2:L#
  plot(v1, err_k10_cat[2:L], #
      xlab='# levels', ylab='kfold error', type='p', pch=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
confmatrix = function(predy, y){#
  matrix = table(predy, y)#
  accuracy = sum(diag(matrix))/sum(matrix)#
  return(list(matrix=matrix,accuracy=accuracy,error=1 - accuracy))#
}
err = rep(-1, 10)#
for(i in 1:10){#
  vals <- naiveBayes(diagnosis, wdbc[train_i,], laplace[i])#
  err[i] <- confmatrix(predict(vals, wdbc[test_i,]))$error#
}
head(wdbc)
err = rep(-1, 10)#
for(i in 1:10){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], laplace[i])#
  err[i] <- confmatrix(predict(vals, wdbc[test_i,]))$error#
}
err = rep(-1, 10)#
for(i in 1:10){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], laplace[i])#
  err[i] <- confmatrix(predict(vals, wdbc[-train_i,]))$error#
}
err = rep(-1, 10)#
for(i in 1:10){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], laplace[i])#
  err[i] <- confmatrix(predict(vals, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
err = rep(-1, 10)#
for(i in 1:10){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], i)#
  err[i] <- confmatrix(predict(vals, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
err = rep(-1, 10)#
for(i in 1:10){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=i)#
  err[i] <- confmatrix(predict(vals, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
err = rep(-1, 20)#
myl = seq(from=0,to=100,by=5)#
for(i in myl){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=i)#
  err[i] <- confmatrix(predict(vals, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
err = rep(-1, 21)#
myl = seq(from=0,to=100,by=5)
for(i in myl){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=i)#
  err[i] <- confmatrix(predict(vals, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
err = rep(-1, 21)#
myl = seq(from=0,to=100,by=5)#
for(i in 1:20){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(vals, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
err = rep(-1, 21)#
myl = seq(from=0,to=100,by=5)#
for(i in 1:21){#
  vals <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(vals, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
library(e1071)#
data(houseVotes84, package='pmml')#
#
#1. For the following problems, consult the HouseVotes84 #
#   data set. #
#
##a. What is the probability that a randomly selected #
##   representative is a Democrat? #
  print(sum(houseVotes84$Class == 'democrat')/nrow(houseVotes84))#
  # probability is 61% it wil be a Democrat#
#
  # alt way: #
  print(table(houseVotes84$Class) / sum(table(houseVotes84$Class)))#
#
##b. Given that a representative is a Republican, what #
##   is the probability that he or she voted for water #
##   project cost sharing? #
#
  repwater <- naiveBayes(V2~Class, houseVotes84)#
#
  ##Verify by hand computation of Bayes formula: #
  rep <- (houseVotes84$Class == 'republican') * 1#
  dem <- (houseVotes84$Class == 'democrat') * 1#
#
  idx <- 1 - (is.na(houseVotes84$V2) * 1) #
  v2 <- houseVotes84$V2[complete.cases(houseVotes84$V2)]#
#
  prob_water = sum( (v2 == 'y') * 1) / length(v2)#
  prob_nwater = sum((v2 == 'n') * 1) / length(v2)#
  prob_rep = sum(rep) / nrow(houseVotes84)#
  prob_dem = sum(dem) / nrow(houseVotes84)#
  p_w_rep = sum( (v2 == 'y') & (rep[idx == 1] > 0) ) / (sum(rep))#
  p_w_dem = sum( (v2 == 'y') & (dem[idx == 1] > 0) ) / (sum(dem))#
#
  # probability is 0.3846154 by both computations.#
#
##c. Given that a representative voted for adoption of the #
##   budget resolution, against the physician fee freeze and #
##   duty free exports, find the probability that he or she #
##   is a Democrat (Hint: if x is a vector, you can use #
##   rbind(x) to force R to treat it as a row vector. You can #
##   set missing values of x to NA, and naive Bayes will #
##   ignore them.)#
###
##      i.e. We're checking probability that#
##        Class == 'democrat' given #
##        V3 = 'y'#
##        V4 = 'n'#
##        V15 = 'n'#
#
  dem3415 <- naiveBayes(Class~V3 + V4 + V15, houseVotes84)#
  dvec <- rbind(rep('NA', 17))#
  dvec[4] <- 'y'#
  dvec[5] <- 'n'#
  dvec[16] <- 'n'#
  predict(dem3415, newdata = dvec, type='raw')
r(1, 2)
c(1, 2)
rbind(1, 2)
c(1, 2)
wdbc <- read.table('~/Dropbox/Tarleton/data_mining/hw05/wdbc.data',#
                     header=F,sep=',')#
  wdbc <- wdbc[,-1]#
  names(wdbc)[1] <- c('diagnosis')#
  for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=c('histogram of ',name))#
  	print(c('Shapiro-Wilk test for ', name, '=', shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i] main=c('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=c('histogram of ',name))#
#  	print(c('Shapiro-Wilk test for ', name, '=', shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i] main=c('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=c('histogram of ',name))
}
for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=c('histogram of ',name))#
  	print(c('Shapiro-Wilk test for ', name, '=', shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=c('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=cat('histogram of ',name))#
  	print(cat(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=cat('Q-Q test for ',name))#
  }
name
hist(wdbc[,i], main=cat('histogram of ',as.character(name)))
for(i in 2:ncol(wdbc)){#
  	name <- as.character(names(wdbc)[i])#
#  	title <- cat('histogram of', as.character(name))#
  	hist(wdbc[,i], main=cat('histogram of ',name))#
  	print(cat(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=cat('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- as.character(names(wdbc)[i])#
#  	title <- cat('histogram of', as.character(name))#
  	hist(wdbc[,i], main=c('histogram of ',name))#
  	print(cat(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=c('Q-Q test for ',name))#
  }
name
for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=c('histogram of ',name))#
  	print(c(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=c('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=c('histogram of ',name))#
  	print(cat(as.character(name), shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=c('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=c('histogram of ',name))#
  	print(cat(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=c('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- names(wdbc)[i]#
  	hist(wdbc[,i], main=c('histogram of ',name))#
  	print(c(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=c('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=cat('histogram of ',name))#
  	print(cat(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=cat('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
#  	print(paste(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(name)#paste(name, shapiro.test(wdbc[,i])))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
shapiro.test(wdbc[,i])
shapiro.test(wdbc[,i])$p
shapiro.test(wdbc[,i])$W
shapiro.test(wdbc[,i])$w
shapiro.test(wdbc[,3])$p
print(paste(name, shapiro.test(wdbc[,4])$p))
shapiro.test(wdbc[,4])$p
shapiro.test(wdbc[,4])
for(i in 2:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
splitset <- splitdata(wdbc, 0.7, FALSE)#
  train_d <- splitset$traindata#
  test_d  <- splitset$testdata#
  train_i <- splitset$train#
#
##a. normally distributed variables#
  pred_diag_n <- naiveBayes(diagnosis ~., wdbc)#
  pred <- predict(pred_diag_n, wdbc)#
  table(pred, wdbc$diagnosis)#
  err_normal = confmatrix(wdbc$diagnosis, pred)$error#
#
##b. categorical variables with 4 levels. #
#
  disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
    disc_wdbc[,j] <- as.factor(cut(wdbc[,j], 4))#
  }#
  pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc)#
  pred <- predict(pred_diag_n, disc_wdbc)#
  table(pred, disc_wdbc$diagnosis)#
  err_cat = confmatrix(disc_wdbc$diagnosis, pred)$error
#dataset functions: #
#
#splitdata - splits a dataframe into test and train sets#
#  inputs: #
#    1. dataset to be split#
#    2. (decimal) percent to be used for training set#
#    3. boolean to decide whether to take a sample with replacement#
#  output: #
#    list of length 3, #
#    list[[1]] = traindata#
#    list[[2]] = testdata#
#    list[[3]] = train (vector of indices from original set for train)#
#
#kfold_val - performs cross-validation on a dataset#
#  inputs:#
#    1. integer (k) for how many folds to use.#
#    2. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    3. data set #
#    4. column index for which variable is being predicted#
#  output: #
#    avg. error for either ctree or rpart w.r.t. dataset#
#
#error_leave_one_out - performs leave-one-out cross-validation.#
#  inputs: #
#    1. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    2. data set #
#    3. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#delete_d_cv - performs delte-d cross validation#
#  inputs: #
#    1. integer: number of times to iterate (m)#
#    2. integer: number of entries to leave out (d)#
#    3. type (0 or 1) for ctree or rpart respectively#
#    4. data set#
#    5. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#bootstrap - performs bootstrap validation#
#  inputs:#
#    1. integer: number of times to iterate (b)#
#    2. type(0 or 1) for (ctree, rpart) resp.#
#    3. data set#
#    4. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#confmatrix - compute the confusionmatrix for a tree w.r.t. #
#             predicted variable V#
#  inputs: #
#    1. V the predicted variable#
#    2. prediction method #
#  outputs: #
#    1. list with entries: #
#       1.1: table of predicted vs. actual V#
#       1.2: accuracy#
#       1.3: error#
#
#standardize - scale data in set with normal #
#  inputs #
#
splitdata = function(data, trainfrac, rep){#
	if((trainfrac > 1) | (trainfrac < 0)){#
		print("error in function splitdata: trainfrac not in [0 1]")#
	}#
#
	tot_size = nrow(data)#
	train_list = sample(tot_size, round(trainfrac * tot_size, digits=0), #
	                    replace = rep)#
	traindata <- data[train_list, ]#
	testdata <- data[-train_list, ]#
	mylist <- list(traindata = traindata, testdata = testdata, train = train_list)#
    return(mylist)#
}#
#
kfold_val = function(k, treetype, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
error_leave_one_out = function(treetype, wdbc, idx){#
	myerror = kfold_val(nrow(wdbc), treetype, wdbc, idx)#
	return(myerror)#
}#
#
delete_d_cv = function(m, d, mytree, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
#
  for(i in 1:m){#
	splitlist <- splitdata(wdbc, 1 - d / nrow(wdbc), FALSE)#
    traindata <- splitlist$traindata#
    testdata <- splitlist$testdata#
    if(mytree < 1){#
      mynewtree = ctree(mynewtestidx~., traindata)#
    }else{#
      mynewtree = rpart(mynewtestidx)~., traindata, type='class')#
    }#
#
    p_tree_train <- predict(mynewtree, testdata)#
#
    m_tree = table(testdata$mynewtestidx, p_tree_train)#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / m#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
bootstrap = function(b, mytree, wdbc, idx){#
	n1 <- names(wdbc)[idx]#
	names(wdbc)[idx] <- 'mynewidx'#
    total_acc = 0#
    n = nrow(wdbc)#
    for(i in 1:b){#
      	 splitlist <- splitdata(wdbc, 1, TRUE)#
      	 traindata <- splitlist$traindata#
      	 testdata <- splitlist$testdata#
      	 if(mytree < 1){#
      	 	mynewtree = ctree(mynewidx~., traindata)#
      	 }else{#
      	    mynewtree = rpart(mynewidx~., traindata)	#
      	 }#
      	 p_tree_train <- predict(mynewtree, testdata)#
   	     m_tree = table(testdata$mynewidx, p_tree_train)#
   	     test_acc = sum(diag(m_tree)) / sum(m_tree)#
   	     total_acc = total_acc + test_acc#
    }#
#
    names(wdbc)[idx] <- n1#
    total_acc = total_acc / b#
    return(1 - total_acc)#
}#
#
euclidean = function(x1, x2){#
  return(sqrt((x1 - x2) %*% (x1 - x2)))#
}#
#
confmatrix = function(predy, y){#
  matrix = table(predy, y)#
  accuracy = sum(diag(matrix))/sum(matrix)#
  return(list(matrix=matrix,accuracy=accuracy,error=1 - accuracy))#
}#
#
standardize = function(myset, cols){#
#
 xbar <- apply(myset[,cols], 2, mean) # mean for each column#
 s <- apply(myset[,cols], 2, sd)      # standard dev. for each col.#
#
 xbarMatrix <- cbind(rep(1,nrow(myset))) %*% xbar # matrix with each row xbar#
 sMatrix <- cbind(rep(1,nrow(myset))) %*% s       # matrix with each row s#
#
 sdized <- (myset[,cols] - xbarMatrix)#
 sdized <- sdized / sMatrix#
 sdized <- cbind(V2 = myset[,1], sdized[,1:ncol(sdized),drop=F])#
#
 return(sdized)#
}
splitset <- splitdata(wdbc, 0.7, FALSE)#
  train_d <- splitset$traindata#
  test_d  <- splitset$testdata#
  train_i <- splitset$train#
#
##a. normally distributed variables#
  pred_diag_n <- naiveBayes(diagnosis ~., wdbc)#
  pred <- predict(pred_diag_n, wdbc)#
  table(pred, wdbc$diagnosis)#
  err_normal = confmatrix(wdbc$diagnosis, pred)$error#
#
##b. categorical variables with 4 levels. #
#
  disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
    disc_wdbc[,j] <- as.factor(cut(wdbc[,j], 4))#
  }#
  pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc)#
  pred <- predict(pred_diag_n, disc_wdbc)#
  table(pred, disc_wdbc$diagnosis)#
  err_cat = confmatrix(disc_wdbc$diagnosis, pred)$error
err_normal
1 - err_normal
err_cat
1 - err_cat
pred_diag_n <- naiveBayes(diagnosis ~., wdbc[train_i,])#
  pred <- predict(pred_diag_n, wdbc[-train_i,])#
  table(pred, wdbc$diagnosis[-train_i])#
  err_normal = confmatrix(wdbc$diagnosis[-train_i,], pred)$error
pred_diag_n <- naiveBayes(diagnosis ~., wdbc[train_i,])#
  pred <- predict(pred_diag_n, wdbc[-train_i,])#
  table(pred, wdbc$diagnosis[-train_i])#
  err_normal = confmatrix(wdbc$diagnosis[-train_i], pred)$error
err_normal
acc_normal = 1 - err_normal
acc_normal
disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
    disc_wdbc[,j] <- as.factor(cut(wdbc[,j], 4))#
  }#
  pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc[train_i,])#
  pred <- predict(pred_diag_n, disc_wdbc[-train_i,])#
  table(pred, disc_wdbc$diagnosis[-train_i])#
  err_cat = confmatrix(disc_wdbc$diagnosis[-train_i], pred)$error
err_cat
1 - err_cat
disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
#    disc_wdbc[,j] <- as.factor(cut(wdbc[,j], 4))#
    disc_wdbc[,j] <- cut(wdbc[,j], 4)#
  }
pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc[train_i,])#
  pred <- predict(pred_diag_n, disc_wdbc[-train_i,])#
  table(pred, disc_wdbc$diagnosis[-train_i])#
  err_cat = confmatrix(disc_wdbc$diagnosis[-train_i], pred)$error
1 - err_cat
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)
err_k10_normal1
1 - err_k10_normal1
nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- as.factor(cut(wdbc[,j], L))#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }#
  v1 = 2:L#
  plot(v1, err_k10_cat[2:L], #
      xlab='# levels', ylab='kfold error', type='p', pch=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
err_k10_cat
nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- cut(wdbc[,j], L)#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }#
  v1 = 2:L#
  plot(v1, err_k10_cat[2:L], #
      xlab='# levels', ylab='kfold error', type='p', pch=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
err_cat
err_k10_cat
nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- cut(wdbc[,j], L)#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }#
  v1 = 2:L#
  plot(v1, err_k10_cat[2:L], #
      xlab='# levels', ylab='kfold error', type='p', pch=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])
err_k10_cat
which.min(err_k10_cat)
1 - err_k10_cat[9]
for(i in 1:12){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
wdbc <- read.table('~/Dropbox/Tarleton/data_mining/hw05/wdbc.data',#
                     header=F,sep=',')#
  wdbc <- wdbc[,-1]#
  names(wdbc)[1] <- c('diagnosis')#
#
  for(i in 1:12){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 2:12){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 2:5){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 6:11){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 12:17){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 18:22){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 23:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 23:27){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 28:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
for(i in 2:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
#  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
#  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }
myl = seq(from=0,to=100,by=5)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
myl = seq(from=0,to=100,by=5)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i,]), houseVotes84$Class[-train_i])#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i,]), houseVotes84$Class[-train_i])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
err
plot(1:21, as.numeric(err))
plot(myl, as.numeric(err),xlab='value for laplace smoothing',ylab='error')
myl = seq(from=0,to=100,by=2)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i,]), houseVotes84$Class[-train_i])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='value for laplace smoothing',ylab='error')
myl = seq(from=0,to=200,by=2)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i,]), houseVotes84$Class[-train_i])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='value for laplace smoothing',ylab='error')
myl = seq(from=0,to=300,by=2)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i,]), houseVotes84$Class[-train_i])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='value for laplace smoothing',ylab='error')
#dataset functions: #
#
#splitdata - splits a dataframe into test and train sets#
#  inputs: #
#    1. dataset to be split#
#    2. (decimal) percent to be used for training set#
#    3. boolean to decide whether to take a sample with replacement#
#  output: #
#    list of length 3, #
#    list[[1]] = traindata#
#    list[[2]] = testdata#
#    list[[3]] = train (vector of indices from original set for train)#
#
#kfold_val - performs cross-validation on a dataset#
#  inputs:#
#    1. integer (k) for how many folds to use.#
#    2. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    3. data set #
#    4. column index for which variable is being predicted#
#  output: #
#    avg. error for either ctree or rpart w.r.t. dataset#
#
#error_leave_one_out - performs leave-one-out cross-validation.#
#  inputs: #
#    1. type (0 or 1) for what type of tree to use #
#       (ctree or rpart resp)#
#    2. data set #
#    3. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#delete_d_cv - performs delte-d cross validation#
#  inputs: #
#    1. integer: number of times to iterate (m)#
#    2. integer: number of entries to leave out (d)#
#    3. type (0 or 1) for ctree or rpart respectively#
#    4. data set#
#    5. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#
#bootstrap - performs bootstrap validation#
#  inputs:#
#    1. integer: number of times to iterate (b)#
#    2. type(0 or 1) for (ctree, rpart) resp.#
#    3. data set#
#    4. column index for which variable is being predicted#
#  outputs: #
#   see kfold_val#
#confmatrix - compute the confusionmatrix for a tree w.r.t. #
#             predicted variable V#
#  inputs: #
#    1. V the predicted variable#
#    2. prediction method #
#  outputs: #
#    1. list with entries: #
#       1.1: table of predicted vs. actual V#
#       1.2: accuracy#
#       1.3: error#
#
#standardize - scale data in set with normal #
#  inputs #
#
splitdata = function(data, trainfrac, rep){#
	if((trainfrac > 1) | (trainfrac < 0)){#
		print("error in function splitdata: trainfrac not in [0 1]")#
	}#
#
	tot_size = nrow(data)#
	train_list = sample(tot_size, round(trainfrac * tot_size, digits=0), #
	                    replace = rep)#
	traindata <- data[train_list, ]#
	testdata <- data[-train_list, ]#
	mylist <- list(traindata = traindata, testdata = testdata, train = train_list)#
    return(mylist)#
}#
#
kfold_val = function(k, treetype, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
error_leave_one_out = function(treetype, wdbc, idx){#
	myerror = kfold_val(nrow(wdbc), treetype, wdbc, idx)#
	return(myerror)#
}#
#
delete_d_cv = function(m, d, mytree, wdbc, idx){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
#
  for(i in 1:m){#
	splitlist <- splitdata(wdbc, 1 - d / nrow(wdbc), FALSE)#
    traindata <- splitlist$traindata#
    testdata <- splitlist$testdata#
    if(mytree < 1){#
      mynewtree = ctree(mynewtestidx~., traindata)#
    }else{#
      mynewtree = rpart(mynewtestidx)~., traindata, type='class')#
    }#
#
    p_tree_train <- predict(mynewtree, testdata)#
#
    m_tree = table(testdata$mynewtestidx, p_tree_train)#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / m#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}#
#
bootstrap = function(b, mytree, wdbc, idx){#
	n1 <- names(wdbc)[idx]#
	names(wdbc)[idx] <- 'mynewidx'#
    total_acc = 0#
    n = nrow(wdbc)#
    for(i in 1:b){#
      	 splitlist <- splitdata(wdbc, 1, TRUE)#
      	 traindata <- splitlist$traindata#
      	 testdata <- splitlist$testdata#
      	 if(mytree < 1){#
      	 	mynewtree = ctree(mynewidx~., traindata)#
      	 }else{#
      	    mynewtree = rpart(mynewidx~., traindata)	#
      	 }#
      	 p_tree_train <- predict(mynewtree, testdata)#
   	     m_tree = table(testdata$mynewidx, p_tree_train)#
   	     test_acc = sum(diag(m_tree)) / sum(m_tree)#
   	     total_acc = total_acc + test_acc#
    }#
#
    names(wdbc)[idx] <- n1#
    total_acc = total_acc / b#
    return(1 - total_acc)#
}#
#
euclidean = function(x1, x2){#
  return(sqrt((x1 - x2) %*% (x1 - x2)))#
}#
#
confmatrix = function(predy, y){#
  matrix = table(predy, y)#
  accuracy = sum(diag(matrix))/sum(matrix)#
  return(list(matrix=matrix,accuracy=accuracy,error=1 - accuracy))#
}#
#
standardize = function(myset, cols){#
#
 xbar <- apply(myset[,cols], 2, mean) # mean for each column#
 s <- apply(myset[,cols], 2, sd)      # standard dev. for each col.#
#
 xbarMatrix <- cbind(rep(1,nrow(myset))) %*% xbar # matrix with each row xbar#
 sMatrix <- cbind(rep(1,nrow(myset))) %*% s       # matrix with each row s#
#
 sdized <- (myset[,cols] - xbarMatrix)#
 sdized <- sdized / sMatrix#
 sdized <- cbind(V2 = myset[,1], sdized[,1:ncol(sdized),drop=F])#
#
 return(sdized)#
}
# Data Mining hw 8#
library(e1071)#
data(houseVotes84, package='pmml')#
#
#1. For the following problems, consult the HouseVotes84 #
#   data set. #
#
##a. What is the probability that a randomly selected #
##   representative is a Democrat? #
  print(sum(houseVotes84$Class == 'democrat')/nrow(houseVotes84))#
  # probability is 61% it wil be a Democrat#
#
  # alt way: #
  print(table(houseVotes84$Class) / sum(table(houseVotes84$Class)))#
#
##b. Given that a representative is a Republican, what #
##   is the probability that he or she voted for water #
##   project cost sharing? #
#
  repwater <- naiveBayes(V2~Class, houseVotes84)#
#
  ##Verify by hand computation of Bayes formula: #
  rep <- (houseVotes84$Class == 'republican') * 1#
  dem <- (houseVotes84$Class == 'democrat') * 1#
#
  idx <- 1 - (is.na(houseVotes84$V2) * 1) #
  v2 <- houseVotes84$V2[complete.cases(houseVotes84$V2)]#
#
  prob_water = sum( (v2 == 'y') * 1) / length(v2)#
  prob_nwater = sum((v2 == 'n') * 1) / length(v2)#
  prob_rep = sum(rep) / nrow(houseVotes84)#
  prob_dem = sum(dem) / nrow(houseVotes84)#
  p_w_rep = sum( (v2 == 'y') & (rep[idx == 1] > 0) ) / (sum(rep))#
  p_w_dem = sum( (v2 == 'y') & (dem[idx == 1] > 0) ) / (sum(dem))#
#
  # probability is 0.3846154 by both computations.#
#
##c. Given that a representative voted for adoption of the #
##   budget resolution, against the physician fee freeze and #
##   duty free exports, find the probability that he or she #
##   is a Democrat (Hint: if x is a vector, you can use #
##   rbind(x) to force R to treat it as a row vector. You can #
##   set missing values of x to NA, and naive Bayes will #
##   ignore them.)#
###
##      i.e. We're checking probability that#
##        Class == 'democrat' given #
##        V3 = 'y'#
##        V4 = 'n'#
##        V15 = 'n'#
#
  dem3415 <- naiveBayes(Class~V3 + V4 + V15, houseVotes84)#
  dvec <- rbind(rep('NA', 17))#
  dvec[4] <- 'y'#
  dvec[5] <- 'n'#
  dvec[16] <- 'n'#
  predict(dem3415, newdata = dvec, type='raw')#
#
#2. Investigate normality of the quantitative variables in the #
#   wdbc.data data set, using Shapiro-Wilk tests, histograms, #
#   and qq-plots. #
  wdbc <- read.table('~/Dropbox/Tarleton/data_mining/hw05/wdbc.data',#
                     header=F,sep=',')#
  wdbc <- wdbc[,-1]#
  names(wdbc)[1] <- c('diagnosis')#
#
  for(i in 2:ncol(wdbc)){#
  	name <- toString(names(wdbc)[i])#
  	hist(wdbc[,i], main=paste('histogram of ',name))#
  	print(paste(name, shapiro.test(wdbc[,i])$p))#
  	qqnorm(wdbc[,i], main=paste('Q-Q test for ',name))#
  }#
#
#3. After splitting wdbc.data into 70% training and 30% test #
#   data, compare the test accuracies of naive Bayes, treating #
#   the quantitative variables as #
#
  splitset <- splitdata(wdbc, 0.7, FALSE)#
  train_d <- splitset$traindata#
  test_d  <- splitset$testdata#
  train_i <- splitset$train#
#
##a. normally distributed variables#
  pred_diag_n <- naiveBayes(diagnosis ~., wdbc[train_i,])#
  pred <- predict(pred_diag_n, wdbc[-train_i,])#
  table(pred, wdbc$diagnosis[-train_i])#
  err_normal = confmatrix(wdbc$diagnosis[-train_i], pred)$error#
#
##b. categorical variables with 4 levels. #
#
  disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
    disc_wdbc[,j] <- cut(wdbc[,j], 4)#
  }#
  pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc[train_i,])#
  pred <- predict(pred_diag_n, disc_wdbc[-train_i,])#
  table(pred, disc_wdbc$diagnosis[-train_i])#
  err_cat = confmatrix(disc_wdbc$diagnosis[-train_i], pred)$error#
#
#4. Use 10-fold cross validation to estimate the accuracy of #
#   naive Bayes on wdbc.data, treating the quantitative #
#   variables as #
#
##a. normally distributed variables#
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)#
#
# 0.6616758#
#
##b. categorical variables with L levels, L = 2, 3, ... , 10.#
  nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- cut(wdbc[,j], L)#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }#
  v1 = 2:L#
  plot(v1, err_k10_cat[2:L], #
      xlab='# levels', ylab='kfold error', type='p', pch=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])#
#
# highest accuracy occurs when the number of levels is: #
which.min(err_k10_cat)#
#
#5. Investigate the effect of the Laplace smoothing argument in #
#   the naiveBayes function. What appears to be the optimal value#
#   for this argument? #
#
myl = seq(from=0,to=300,by=2)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i,]), houseVotes84$Class[-train_i])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='value for laplace smoothing',ylab='error')
splitset1 <- splitdata(houseVotes84, 0.7, FALSE)#
  train_d1 <- splitset1$traindata#
  test_d1  <- splitset1$testdata#
  train_i1 <- splitset1$train#
#
myl = seq(from=0,to=300,by=2)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='value for laplace smoothing',ylab='error')
myl = seq(from=0,to=300,by=2)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='value for laplace smoothing',ylab='error')
myl = seq(from=0,to=100,by=2)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=100,by=1)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=500,by=1)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=1000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
kfold_val = function(k, treetype, wdbc, idx, val){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
    }else if(treetype < 4){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata, val)    	#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}
myl = seq(from=0,to=1000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
#  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
err[i] <- kfold_val(10, 2, wdbc, myl[i])#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
myl = seq(from=0,to=1000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
#  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=10,by=1)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
#  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
kfold_val = function(k, treetype, wdbc, idx, val = 0){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
    }else if(treetype < 4){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata, val)    	#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}
kfold_val = function(k, treetype, wdbc, idx, val = 0){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
      print('Hah')#
    }else if(treetype < 4){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata, val)    	#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(predict(pred, houseVotes84[-train_i1,]), houseVotes84$Class[-train_i1])$error#
#err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=5,by=0.5)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(#
          predict(pred, houseVotes84[-train_i1,]), #
          houseVotes84$Class[-train_i1])$error#
#
#  err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=5,by=0.5)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(#
          predict(pred, houseVotes84[-train_i1,]), #
          houseVotes84$Class[-train_i1])$error#
#
#  err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=15,by=1.5)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(#
          predict(pred, houseVotes84[-train_i1,]), #
          houseVotes84$Class[-train_i1])$error#
#
#  err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=150,by=1)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(#
          predict(pred, houseVotes84[-train_i1,]), #
          houseVotes84$Class[-train_i1])$error#
#
#  err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=500,by=5)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(#
          predict(pred, houseVotes84[-train_i1,]), #
          houseVotes84$Class[-train_i1])$error#
#
#  err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
help(naiveBayes)
myl = seq(from=0,to=5000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  err[i] <- confmatrix(#
          predict(pred, houseVotes84[-train_i1,]), #
          houseVotes84$Class[-train_i1])$error#
#
#  err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=5000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  err[i] <- kfold_val(10, 2, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
myl = seq(from=0,to=5000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  err[i] <- kfold_val(10, 3, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
myl = seq(from=0,to=5000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  err[i] <- kfold_val(2, 3, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
kfold_val = function(k, treetype, wdbc, idx = 1, val = 0){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
    }else if(treetype < 4){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata, laplace = val)    	#
    }#
    p_tree_train <- predict(mynewtree, testdata)#
    m_tree = table(testdata$mynewtestidx[myvec==i], p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}
myl = seq(from=0,to=5000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  err[i] <- kfold_val(2, 3, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
kfold_val = function(k, treetype, wdbc, idx = 1, val = 0){#
  total_acc = 0#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
      p_tree_train <- predict(mynewtree, testdata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
      p_tree_train <- predict(mynewtree, testdata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
      p_tree_train <- predict(mynewtree, testdata)#
    }else if(treetype < 4){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata, laplace = val)    	#
      p_tree_train <- predict(mynewtree, testdata)#
    }#
    m_tree = table(testdata$mynewtestidx, p_tree_train)#
#
    test_acc = (sum(diag(m_tree)) / sum(m_tree))#
    total_acc = total_acc + test_acc#
  }#
  total_acc = total_acc / k#
  names(wdbc)[idx] <- n1#
  return(1 - total_acc)#
}
myl = seq(from=0,to=5000,by=10)#
len=length(myl)#
err = rep(-1, len)#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  err[i] <- kfold_val(2, 3, houseVotes84, 1, myl[i])#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
#
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
kfold_val = function(k, treetype, wdbc, idx = 1, val = 0){#
  test_acc <- rep(-1, k)#
#
  n1 <- names(wdbc)[idx]#
  names(wdbc)[idx] <- 'mynewtestidx'#
  size = ceiling(nrow(wdbc)/k)#
  folds = sample(rep(1:k,size))#
  myvec = folds[1:nrow(wdbc)]#
#
  for(i in 1:k){#
#
    testdata <- wdbc[myvec==i,]#
    traindata <- wdbc[myvec!=i,]#
    if(treetype < 1){#
      mynewtree <- ctree(mynewtestidx~., traindata)#
      p_tree_train <- predict(mynewtree, testdata)#
    }else if(treetype < 2){#
      mynewtree <- rpart(mynewtestidx~., traindata)#
      p_tree_train <- predict(mynewtree, testdata)#
    }else if(treetype < 3){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata)#
      p_tree_train <- predict(mynewtree, testdata)#
    }else if(treetype < 4){#
      mynewtree <- naiveBayes(mynewtestidx~., traindata, laplace = val)    	#
      p_tree_train <- predict(mynewtree, testdata)#
    }#
    m_tree = table(testdata$mynewtestidx, p_tree_train)#
#
    test_acc[i] = (sum(diag(m_tree)) / sum(m_tree))#
  }#
  total_acc = sum(test_acc) / k#
  names(wdbc)[idx] <- n1#
#
#  return(1 - total_acc)#
  mynewlist <- list(error = 1 - total_acc, accuracy = 1 - test_acc)#
  return(mynewlist)#
}
myl = seq(from=0,to=5000,by=10)#
len=length(myl)#
k = 2#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(2, 3, houseVotes84, 1, myl[i])#
  err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, k_errs_for_plot[1,], col=1)#
for(i in 1:k){#
	lines(myl, k_errs_for_plot[i,], 5*i)#
}
myl = seq(from=0,to=100,by=10)#
len=length(myl)#
k = 2#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(2, 3, houseVotes84, 1, myl[i])#
  err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
k_errs_for_plot
plot(myl, k_errs_for_plot[,1], col=1)#
for(i in 2:k){#
	lines(myl, k_errs_for_plot[,i], 5*i)#
}
plot(myl, k_errs_for_plot[,1], col=1)#
for(i in 2:k){#
	lines(myl, k_errs_for_plot[,i], col=5*i)#
}
plot(myl, k_errs_for_plot[,1], type='p',col=1)#
for(i in 2:k){#
	lines(myl, k_errs_for_plot[,i], type='p',col=5*i)#
}
myl = seq(from=0,to=1000,by=10)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
plot(myl, k_errs_for_plot[,1], type='p',col=1)#
for(i in 2:k){#
	lines(myl, k_errs_for_plot[,i], type='p',col=5*i)#
}
ylabel1 <- paste('error for ',asString(k),'-fold cv')#
plot(myl, k_errs_for_plot[,1], type='p',col=1, ylab=ylabal1)#
for(i in 2:k){#
  ylabel1 <- paste('error for ',asString(k),'-fold cv')#
  lines(myl, k_errs_for_plot[,i], type='p',col=5*i)#
}
plot(myl, k_errs_for_plot[,1], type='p',col=1, ylab="error")#
for(i in 2:k){#
  lines(myl, k_errs_for_plot[,i], type='p',col=5*i)#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
plot(myl, k_errs_for_plot[,1], type='p',col=1, ylab="error")#
for(i in 2:k){#
  lines(myl, k_errs_for_plot[,i], type='p',col=5*i)#
}
mylegend = ''#
for(i in 1:k){#
  mylegend <- paste(mylegend, 'k = ', toString(i), ',')#
}
plot(myl, k_errs_for_plot[,1], type='p',col=1, ylab="error")#
for(i in 2:k){#
  lines(myl, k_errs_for_plot[,i], type='p',col=5*i)#
}#
legend(mylegend[1:k])
legend(1, 1, mylegend[1:k])
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col=2, ylab='error')#
for(j in 2:k){#
plot(myl, k_errs_for_plot[,j], type='p',col=1, ylab='error')#
#
}#
}
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col=2, ylab='error')#
for(j in 2:k){#
lines(myl, k_errs_for_plot[,j], type='p',col=1)#
#
}#
}
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col=5, ylab='error')#
for(j in 2:k){#
lines(myl, k_errs_for_plot[,j], type='p',col=1)#
#
}#
}
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error')#
for(j in 2:k){#
lines(myl, k_errs_for_plot[,j], type='p',col='black')#
#
}#
}
for(i in 1:k){#
for(j in 2:k){#
plot(myl, k_errs_for_plot[,j], type='p',col='black', ylab='error')#
#
}#
lines(myl, k_errs_for_plot[,i], type='p',col='red')#
}
for(i in 1:k){#
  for(j in 1:k){#
  	if(j != i){#
      plot(myl, k_errs_for_plot[,j], type='p',col='black', ylab='error')#
    }#
  }#
lines(myl, k_errs_for_plot[,i], type='p',col='red')#
}
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error')#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error')#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
splitset1 <- splitdata(houseVotes84, 0.9, FALSE)#
  train_d1 <- splitset1$traindata#
  test_d1  <- splitset1$testdata#
  train_i1 <- splitset1$train#
#
myl = seq(from=0,to=1000,by=10)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
  # pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
  # err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
          # predict(pred, houseVotes84[-train_i1,]), #
          # houseVotes84$Class[-train_i1])$error#
#
#  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
           predict(pred, houseVotes84[-train_i1,]), #
           houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error', main=paste('k = ', toString(i)))#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error', main=paste('fold # ', toString(i)))#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}
err
plot(1:100, err)
plot(1:101, err)
repwater <- naiveBayes(V2~Class, houseVotes84)
repwater
head(houseVotes84)
dem3415 <- naiveBayes(Class~V3 + V4 + V15, houseVotes84)#
  dvec <- rbind(rep('NA', 17))#
  dvec[4] <- 'y'#
  dvec[5] <- 'n'#
  dvec[16] <- 'n'#
  predict(dem3415, newdata = dvec, type='raw')
dem3415 <- naiveBayes(Class~V3 + V4 + V15, houseVotes84)#
  dvec <- rbind(rep('NA', 17))#
  dvec[4] <- 'y'#
  dvec[5] <- 'n'#
  dvec[16] <- 'y'#
  predict(dem3415, newdata = dvec, type='raw')
library(e1071)#
data(houseVotes84, package='pmml')#
#
#1. For the following problems, consult the HouseVotes84 #
#   data set. #
#
##a. What is the probability that a randomly selected #
##   representative is a Democrat? #
  print(sum(houseVotes84$Class == 'democrat')/nrow(houseVotes84))#
  # probability is 61% it wil be a Democrat#
#
  # alt way: #
  print(table(houseVotes84$Class) / sum(table(houseVotes84$Class)))#
#
##b. Given that a representative is a Republican, what #
##   is the probability that he or she voted for water #
##   project cost sharing? #
#
  repwater <- naiveBayes(V2~Class, houseVotes84)#
#
  ##Verify by hand computation of Bayes formula: #
  rep <- (houseVotes84$Class == 'republican') * 1#
  dem <- (houseVotes84$Class == 'democrat') * 1#
#
  idx <- 1 - (is.na(houseVotes84$V2) * 1) #
  v2 <- houseVotes84$V2[complete.cases(houseVotes84$V2)]#
#
  prob_water = sum( (v2 == 'y') * 1) / length(v2)#
  prob_nwater = sum((v2 == 'n') * 1) / length(v2)#
  prob_rep = sum(rep) / nrow(houseVotes84)#
  prob_dem = sum(dem) / nrow(houseVotes84)#
  p_w_rep = sum( (v2 == 'y') & (rep[idx == 1] > 0) ) / (sum(rep))#
  p_w_dem = sum( (v2 == 'y') & (dem[idx == 1] > 0) ) / (sum(dem))#
#
  # probability is 0.3846154 by both computations.#
#
##c. Given that a representative voted for adoption of the #
##   budget resolution, against the physician fee freeze and #
##   for duty free exports, find the probability that he or she #
##   is a Democrat (Hint: if x is a vector, you can use #
##   rbind(x) to force R to treat it as a row vector. You can #
##   set missing values of x to NA, and naive Bayes will #
##   ignore them.)#
###
##      i.e. We're checking probability that#
##        Class == 'democrat' given #
##        V3 = 'y'#
##        V4 = 'n'#
##        V15 = 'y'#
#
  dem3415 <- naiveBayes(Class~V3 + V4 + V15, houseVotes84)#
  dvec <- rbind(rep('NA', 17))#
  dvec[4] <- 'y'#
  dvec[5] <- 'n'#
  dvec[16] <- 'y'#
  predict(dem3415, newdata = dvec, type='raw')
pred_diag_n <- naiveBayes(diagnosis ~., wdbc[train_i,])#
  pred <- predict(pred_diag_n, wdbc[-train_i,])#
  table(pred, wdbc$diagnosis[-train_i])#
  err_normal = confmatrix(wdbc$diagnosis[-train_i], pred)$error
disc_wdbc <- wdbc#
  for (j in 2:ncol(wdbc)){#
    disc_wdbc[,j] <- cut(wdbc[,j], 4)#
  }#
  pred_diag_n <- naiveBayes(diagnosis ~., disc_wdbc[train_i,])#
  pred <- predict(pred_diag_n, disc_wdbc[-train_i,])#
  table(pred, disc_wdbc$diagnosis[-train_i])#
  err_cat = confmatrix(disc_wdbc$diagnosis[-train_i], pred)$error
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)
err_k10_cat
err_k10_normal1
err_k10_normal1 <- kfold_val(10, 2, wdbc, 1)$error
err_k10_normal1
nlevels = 10#
  err_k10_cat <- 1:nlevels#
#
  for(L in 2:nlevels){#
    disc <- wdbc#
    for(j in 2:ncol(wdbc)){#
      disc[,j] <- cut(wdbc[,j], L)#
    }#
    err_k10_cat[L] <- kfold_val(10, 2, disc, 1)#
  }#
  v1 = 2:L#
  plot(v1, err_k10_cat[2:L], #
      xlab='# levels', ylab='kfold error', type='p', pch=16,#
      col=c('black','blue',#
            'green','yellow',#
            'orange','red',#
            'purple','brown',#
            'gray','pink')[v1])#
#
# highest accuracy occurs when the number of levels is: #
which.min(err_k10_cat)
err_k10_cat[6]
1 - err_k10_cat[6]
1 - as.numeric(err_k10_cat[6])
splitset1 <- splitdata(houseVotes84, 0.9, FALSE)#
  train_d1 <- splitset1$traindata#
  test_d1  <- splitset1$testdata#
  train_i1 <- splitset1$train
myl = seq(from=0,to=5000,by=20)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
           predict(pred, houseVotes84[-train_i1,]), #
           houseVotes84$Class[-train_i1])$error#
#
#  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
#  err[i] <- l$error#
#  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
splitset1 <- splitdata(houseVotes84, 0.7, FALSE)#
  train_d1 <- splitset1$traindata#
  test_d1  <- splitset1$testdata#
  train_i1 <- splitset1$train#
#
myl = seq(from=0,to=5000,by=20)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
           predict(pred, houseVotes84[-train_i1,]), #
           houseVotes84$Class[-train_i1])$error#
#
#  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
#  err[i] <- l$error#
#  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
splitset1 <- splitdata(houseVotes84, 0.7, FALSE)#
  train_d1 <- splitset1$traindata#
  test_d1  <- splitset1$testdata#
  train_i1 <- splitset1$train#
#
myl = seq(from=0,to=5000,by=20)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
           predict(pred, houseVotes84[-train_i1,]), #
           houseVotes84$Class[-train_i1])$error#
#
#  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
#  err[i] <- l$error#
#  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
for(i in 1:len){#
#
#   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
#   err[i] <- confmatrix(#
#           predict(pred, houseVotes84[-train_i1,]), #
#           houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error')
mylegend = rep(' ', k)#
for(i in 1:k){#
  mylegend[i] <- paste('k = ', toString(i), ', ')#
}#
#plot(myl, k_errs_for_plot[,1], type='p',col=1, ylab="error")#
#for(i in 2:k){#
#  lines(myl, k_errs_for_plot[,i], type='p',col=5*i)#
#}#
#
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error', main=paste('fold # ', toString(i)))#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}#
legend(mylegend[1:k])
for(i in 1:len){#
#
#   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
#   err[i] <- confmatrix(#
#           predict(pred, houseVotes84[-train_i1,]), #
#           houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
#  pred <- naiveBayes(diagnosis~., wdbc[train_i,], laplace=myl[i])#
#  err[i] <- confmatrix(predict(pred, wdbc[-train_i,]), wdbc[-train_i,]$diagnosis)$error#
}#
mylegend = rep(' ', k)#
for(i in 1:k){#
  mylegend[i] <- paste('k = ', toString(i), ', ')#
}#
#plot(myl, k_errs_for_plot[,1], type='p',col=1, ylab="error")#
#for(i in 2:k){#
#  lines(myl, k_errs_for_plot[,i], type='p',col=5*i)#
#}#
#
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error', main=paste('fold # ', toString(i)))#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}
plot(myl, as.numeric(k_err),xlab='Value for laplace smoothing',ylab='error', main='naiveBayes with k-fold cv and varying laplace')
plot(myl, as.numeric(err),xlab='Value for laplace smoothing',ylab='error', main='naiveBayes with k-fold cv and varying laplace')
myl = seq(from=0,to=1,by=0.05)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
           predict(pred, houseVotes84[-train_i1,]), #
           houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  k_err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
}#
#
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error', main=paste('fold # ', toString(i)))#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}#
#
plot(myl, as.numeric(k_err),xlab='Value for laplace smoothing',ylab='error', main='naiveBayes with k-fold cv and varying laplace')
myl = seq(from=0,to=1,by=0.05)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
           predict(pred, houseVotes84[-train_i1,]), #
           houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  k_err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
}#
#
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error', main=paste('fold # ', toString(i)))#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}#
#
plot(myl, as.numeric(k_errs),xlab='Value for laplace smoothing',ylab='error', main='naiveBayes with k-fold cv and varying laplace')
myl = seq(from=0,to=1,by=0.05)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
           predict(pred, houseVotes84[-train_i1,]), #
           houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  k_err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
}#
#
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error', main=paste('fold # ', toString(i)))#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}#
#
plot(myl, as.numeric(k_err),xlab='Value for laplace smoothing',ylab='error', main='naiveBayes with k-fold cv and varying laplace')
myl = seq(from=0,to=3,by=0.15)#
len=length(myl)#
k = 10#
#
err = rep(-1, len)#
k_err = rep(-1, len)#
k_errs_for_plot <- matrix(, nrow=len, ncol=k)#
#
for(i in 1:len){#
#
   pred <- naiveBayes(Class~., houseVotes84[train_i1,], laplace=myl[i])#
   err[i] <- confmatrix(#
           predict(pred, houseVotes84[-train_i1,]), #
           houseVotes84$Class[-train_i1])$error#
#
  l <- kfold_val(k, 3, houseVotes84, 1, myl[i])#
  k_err[i] <- l$error#
  k_errs_for_plot[i,] <- l$accuracy#
#
}#
#
for(i in 1:k){#
plot(myl, k_errs_for_plot[,i], type='p',col='red', ylab='error', main=paste('fold # ', toString(i)))#
  for(j in 1:k){#
  	if(j != i){#
      lines(myl, k_errs_for_plot[,j], type='p',col='black')#
    }#
  }#
}#
#
plot(myl, as.numeric(k_err),xlab='Value for laplace smoothing',ylab='error',#
      main='naiveBayes with k-fold cv and varying laplace')
